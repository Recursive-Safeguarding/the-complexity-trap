# llm_summary hyperparameter search

program: scripts/run_sweep.py
method: bayes
metric: {name: submission_rate, goal: maximize}

parameters:
  model: {values: [deepseek-chat, bedrock-qwen3-32b, glm-4.6, kimi-k2, minimax-m2, gpt-4o-mini]}
  strategy: {value: llm_summary}
  summarizer-model: {values: [deepseek-chat, bedrock-qwen3-32b, glm-4.6, kimi-k2, minimax-m2, gpt-4o-mini]}
  instances-subset: {value: verified-mini}
  instances-shuffle: {value: true}
  instances-shuffle-seed: {value: 42}
  call-limit: {value: 250}
  cost-limit: {value: 0.0}
  num-workers: {value: 1}
  hp-sum-n: {values: [15, 21, 28]}
  hp-sum-keep-m: {values: [7, 10, 12]}
  hp-sum-static-checkpoint: {values: [true, false]}
  hp-sum-extract-actions: {values: [true, false]}

command:
  - ${env}
  - python
  - ${program}
  - ${args}
  - --wandb
  - --wandb-project=complexity-trap-hparams
